{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Explainable-AI\" data-toc-modified-id=\"Explainable-AI-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Explainable AI</a></span><ul class=\"toc-item\"><li><span><a href=\"#Components-of-the-explanation\" data-toc-modified-id=\"Components-of-the-explanation-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Components of the explanation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Surrogate-Models\" data-toc-modified-id=\"Surrogate-Models-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Surrogate Models</a></span></li><li><span><a href=\"#Correlation-Plots\" data-toc-modified-id=\"Correlation-Plots-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Correlation Plots</a></span></li><li><span><a href=\"#Data-Projection\" data-toc-modified-id=\"Data-Projection-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Data Projection</a></span></li><li><span><a href=\"#LIME-Models\" data-toc-modified-id=\"LIME-Models-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>LIME Models</a></span></li><li><span><a href=\"#Leave-one-covariate-out-(LOCO)\" data-toc-modified-id=\"Leave-one-covariate-out-(LOCO)-1.1.5\"><span class=\"toc-item-num\">1.1.5&nbsp;&nbsp;</span>Leave one covariate out (LOCO)</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainable AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this document we will look at some ways on how to approach the task of explaining the predictions coming out of the so called black box models. This approach is model agnostic meaning that it won't change with respect to the models it is being used to explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components of the explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will outline the components that will be used to give a holistic explanation for the predictions the model is making and also to give a sense of the data to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will provide four-five components to the user to understand the\n",
    "- decision making process\n",
    "- variable importance at global level\n",
    "- variable importance at instance level\n",
    "- effect of changing the value of a variable while keeping others constant\n",
    "- two dimensional projection of the data in case of classification\n",
    "- correlation plots for user to get an idea of how the variables are related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Surrogate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will mostly be relying on decision trees to act as surrogate models. The idea is to take the predictions of the model and fit a decision tree to it. Since decision trees are easy to understand and visualize, this will give the user an approximate idea of how the prediction process works. \n",
    "\n",
    "Also, this visualization sheds light on variable importance as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation plots are easier to understand than the normally used correlation matrix to convey to the user as to how the variables are correlated. In this plot, thicker connecting lines indicate higher correlation value. \n",
    "<img src='https://d3ansictanv2wj.cloudfront.net/figure_3-5a3910aac95a46ff5b2022371a1fdd8c.jpg', width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data projection is particularly useful for classification exercises, where we can show how well the different classes are organized. Ideally, this projection has to be in two or maximum three dimensions. This can be achieved using either of these - PCA, MDS, t-SNE or Autoencoders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LIME Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIME (Locally Interpretable Model agnostic Explanations) is a method for building linear monotonous models that can be interpreted in the region they are applied in. LIME is useful for breaking down the non linear response variable into multiple linear models. The coefficients of the variables from this model help explain the model predictions at an instance level. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this method, we can list variables according to their importance for a particular instance even in the case of non linear models where coefficients are not explicitly present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leave one covariate out (LOCO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach, we will build a model, with the same parameters but will exclude one variable out of the modeling process and show the comparison between predictions when a particular variable is to be excluded. This will help explain the variable importance at a prediction level. Variables which on exclusion, bring about the most change will be marked as most important for that instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: This process maybe computationally expensive and should preferably be used for continuous variables only. "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
